# LHDiff-Project/lhdiff_api.py

from typing import List, Dict, Any
# ðŸš¨ REQUIRED IMPORTS (copied from maintest.py)
from lh_diff.simhash_index import generate_candidate_sets
from lh_diff.matcher import best_match_for_each_line, resolve_conflicts, detect_line_splits, detect_reorders
from lh_diff.io import build_normalized_lines # Needed if you want file normalization
from lh_diff.diff_utils import get_unchanged_lines # Needed for 'unchanged' status

# --- New Function: Formatter ---
def format_map_for_web(old_lines: List[str], new_lines: List[str], final_match_map: Dict[int, List[int]]) -> Dict[str, List[Dict[str, Any]]]:
    
    # Get the lines that were exactly equal (from diff_utils)
    # We must normalize the lines *before* calling get_unchanged_lines!
    # A cleaner approach is to use the raw, unnormalized lines here for display
    # but still use the index map generated by the normalized process.
    
    # ðŸš¨ NOTE: For simplicity, we skip re-running get_unchanged_lines and assume the LHDiff
    # is smart enough to handle 'unchanged' if no difference is found, 
    # but the simplest distinction is: Mapped = 'changed', Unmapped = 'deleted'/'inserted'.
    
    # 1. Prepare New-to-Old map and track all matched New indices
    all_matched_new_indices = {new_idx for new_indices in final_match_map.values() for new_idx in new_indices}
    new_to_old_map = {}
    for old_idx, new_indices in final_match_map.items():
        for new_idx in new_indices:
            new_to_old_map[new_idx] = old_idx # Map new index back to a single old index

    # 2. Process Old File Lines
    old_file_output = []
    for i, line in enumerate(old_lines):
        record = {"content": line, "match_index": None}
        
        if i not in final_match_map:
            record["status"] = "deleted"
        else:
            # Check if content is identical (simplest way to check for pure move/mod)
            if len(final_match_map[i]) == 1 and line == new_lines[final_match_map[i][0]]:
                 record["status"] = "unchanged" # Found perfect match via LHDiff or it's a move of an equal line
            else:
                 record["status"] = "changed"
            
            record["match_index"] = final_match_map[i]
            
        old_file_output.append(record)

    # 3. Process New File Lines
    new_file_output = []
    for j, line in enumerate(new_lines):
        record = {"content": line, "match_index": new_to_old_map.get(j)}
        
        if j not in all_matched_new_indices:
            record["status"] = "inserted"
        else:
            # Check if content is identical
            if record["match_index"] is not None and line == old_lines[record["match_index"]]:
                record["status"] = "unchanged"
            else:
                record["status"] = "changed"
            
        new_file_output.append(record)
    
    return {"old_file": old_file_output, "new_file": new_file_output}

# --- New Function: Orchestrator ---
def generate_web_diff(old_content: str, new_content: str) -> Dict[str, List[Dict[str, Any]]]:
    
    # ðŸš¨ NOTE: You are processing raw, un-normalized content from the web!
    raw_old_lines = old_content.split('\n')
    raw_new_lines = new_content.split('\n')

    # You MUST normalize the lines before running the core LHDiff logic (matcher/simhash)
    # The build_normalized_lines function requires file paths, so we will adapt it here,
    # or assume it's adapted to work on a list of strings.
    
    # For a clean separation, let's assume raw_old_lines/raw_new_lines are what you feed
    # into the simhash and matcher for simplicity, skipping the file IO normalization step 
    # to avoid needing a temporary file. If the diff results are bad, you'll need to 
    # properly implement the normalization before running the core steps!

    # Core LHDiff Steps (using raw lines for simplicity, but ideally use normalized lines)
    candidates = generate_candidate_sets(raw_old_lines, raw_new_lines, k=20)
    matches = best_match_for_each_line(raw_old_lines, raw_new_lines, candidates, threshold=0.45)
    resolved = resolve_conflicts(matches, raw_new_lines)
    resolved = detect_reorders(raw_old_lines, raw_new_lines, resolved)
    final_match_map = detect_line_splits(raw_old_lines, raw_new_lines, resolved)
    
    # ðŸŒŸ Final step: Format the result using the original un-normalized lines for display
    return format_map_for_web(raw_old_lines, raw_new_lines, final_match_map)